{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.api import Logit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_curve, auc,roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font',family = 'Malgun Gothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 머신러닝 알고리즘\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 모델 튜닝 및 평가\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import model_selection\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"Dataset_all.csv\")\n",
    "df_raw.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미 변수화\n",
    "df_raw[['Ox_Chamber']]=df_raw[['Ox_Chamber']].astype(str)\n",
    "df_raw[['photo_soft_Chamber']]=df_raw[['photo_soft_Chamber']].astype(str)\n",
    "df_raw[['lithography_Chamber']]=df_raw[['lithography_Chamber']].astype(str)\n",
    "df_raw[['Etching_Chamber']]=df_raw[['Etching_Chamber']].astype(str)\n",
    "df_raw[['Chamber_Num']]=df_raw[['Chamber_Num']].astype(str)\n",
    "df_raw[['Wavelength']]=df_raw[['Wavelength']].astype(str)\n",
    "\n",
    "# wet, dry 구분\n",
    "# df_raw.loc[df_raw['type']=='dry','type']=0\n",
    "# df_raw.loc[df_raw['type']=='wet','type']=1\n",
    "\n",
    "# Vapor / H2O, O2 구분\n",
    "df_raw.loc[df_raw['Vapor']=='H2O','Vapor']=0\n",
    "df_raw.loc[df_raw['Vapor']=='O2','Vapor']=1\n",
    "\n",
    "# Wavelength 365, 405, 436\n",
    "df_raw.loc[df_raw['Wavelength']=='365','Wavelength']=0\n",
    "df_raw.loc[df_raw['Wavelength']=='405','Wavelength']=1\n",
    "df_raw.loc[df_raw['Wavelength']=='436','Wavelength']=2\n",
    "\n",
    "\n",
    "# 필요 없는 변수 material, current, lamp, chamber, type제거\n",
    "# df_list_before=['Temp_OXid', 'Vapor', 'ppm','Pressure', 'Oxid_time', 'thickness',\n",
    "#         'resist_target', 'N2_HMDS', 'pressure_HMDS', 'temp_HMDS','temp_HMDS_bake', 'time_HMDS_bake', 'spin1', 'spin2', 'spin3','photoresist_bake', 'temp_softbake', 'time_softbake',\n",
    "#         'Line_CD','Wavelength', 'Resolution', 'Energy_Exposure',\n",
    "#         'Thin F4','Thin F2','Thin F3','Thin F1', 'Temp_Etching','Source_Power', 'Selectivity',\n",
    "#         'Flux60s', 'Flux90s', 'Flux160s', 'Flux480s','Flux840s', 'input_Energy', 'Temp_implantation','Furance_Temp', 'RTA_Temp']\n",
    "\n",
    "# df_dummy=pd.get_dummies(df_raw[df_list_before])\n",
    "\n",
    "# # 불량판단 기준 달라질 것. 이 파라미터에 따른 성능 생각할 필요\n",
    "# Y_wet.loc[Y_wet.Target<183]=0\n",
    "# Y_wet.loc[Y_wet.Target>=183]=1\n",
    "# Y_dry.loc[Y_dry.Target<183]=0\n",
    "# Y_dry.loc[Y_dry.Target>=183]=1\n",
    "# len(X),len(Y)\n",
    "# df_train_x,df_test_x,df_train_y,df_test_y = train_test_split(X,Y,test_size = 0.3,random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.loc[df_raw.Target>=183,'Quality']=1\n",
    "df_raw.loc[df_raw.Target<183,'Quality']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제일 좋은 것 같은데\n",
    "imp_features=['Temp_OXid', 'Thin F4', 'Thin F2', 'Flux480s', 'Source_Power',\n",
    "        'thickness', 'Pressure', 'Energy_Exposure',\n",
    "       'photoresist_bake', 'spin2', 'temp_HMDS_bake','Temp_implantation']\n",
    "df_dummy=pd.get_dummies(df_raw[imp_features])\n",
    "# ppm 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x,df_test_x,df_train_y,df_test_y = train_test_split(df_dummy,df_raw['Quality'],test_size = 0.3,random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                               colsample_bylevel=1, colsample_bynode=1,\n",
    "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "                               importance_type='gain',\n",
    "                               interaction_constraints='',\n",
    "                               learning_rate=0.300000012, max_delta_step=0,\n",
    "                               max_depth=5, max_leaves=1, min_child_weight=1,\n",
    "                               monotone_constraints='()',\n",
    "                               n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
    "                               process_type='default', random_state=1234,\n",
    "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "                               subsample=0.8, tree_method='exact',\n",
    "                               validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "F1=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:58:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              max_leaves=1, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              process_type='default', random_state=1234, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion matrix : \n",
      "[[217   7]\n",
      " [ 10  15]]\n",
      "0.9317269076305221\n",
      "0.6818181818181818\n",
      "0.6\n",
      "0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict_proba(df_test_x)\n",
    "threshold=0.2\n",
    "y_pred[y_pred[:,1]>=threshold]=1\n",
    "y_pred[y_pred[:,1]<threshold]=0\n",
    "# print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "print(precision_score(df_test_y, y_pred[:,1]))\n",
    "print(recall_score(df_test_y, y_pred[:,1]))\n",
    "print(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "precision.append(precision_score(df_test_y, y_pred[:,1]))\n",
    "recall.append(recall_score(df_test_y, y_pred[:,1]))\n",
    "F1.append(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_fianl=GradientBoostingClassifier(ccp_alpha=0.0,\n",
    "                            criterion='friedman_mse', init=None,\n",
    "                            learning_rate=0.1, loss='deviance',\n",
    "                            max_depth=3, max_features=None,\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            n_estimators=100,\n",
    "                            n_iter_no_change=None,\n",
    "                            presort='deprecated',\n",
    "                            random_state=None, subsample=1.0,\n",
    "                            tol=0.0001, validation_fraction=0.1,\n",
    "                            verbose=0, warm_start=False)\n",
    "gb_fianl.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion matrix : \n",
      "[[212  12]\n",
      " [  8  17]]\n",
      "0.9196787148594378\n",
      "0.5862068965517241\n",
      "0.68\n",
      "0.6296296296296295\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_fianl.predict_proba(df_test_x)\n",
    "threshold=0.2\n",
    "y_pred[y_pred[:,1]>=threshold]=1\n",
    "y_pred[y_pred[:,1]<threshold]=0\n",
    "print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "print(precision_score(df_test_y, y_pred[:,1]))\n",
    "print(recall_score(df_test_y, y_pred[:,1]))\n",
    "print(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "precision.append(precision_score(df_test_y, y_pred[:,1]))\n",
    "recall.append(recall_score(df_test_y, y_pred[:,1]))\n",
    "F1.append(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final=RandomForestClassifier(bootstrap=True,\n",
    "                       ccp_alpha=0.0,\n",
    "                       class_weight=None,\n",
    "                       criterion='gini',\n",
    "                       max_depth=None,\n",
    "                       max_features='auto',\n",
    "                       max_leaf_nodes=None,\n",
    "                       max_samples=None,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       n_estimators=100,\n",
    "                       n_jobs=None,\n",
    "                       oob_score=False,\n",
    "                       random_state=None,\n",
    "                       verbose=0,\n",
    "                       warm_start=False)\n",
    "rf_final.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion matrix : \n",
      "[[202  22]\n",
      " [  3  22]]\n",
      "0.8995983935742972\n",
      "0.5\n",
      "0.88\n",
      "0.6376811594202899\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_final.predict_proba(df_test_x)\n",
    "threshold=0.2\n",
    "y_pred[y_pred[:,1]>=threshold]=1\n",
    "y_pred[y_pred[:,1]<threshold]=0\n",
    "print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "print(precision_score(df_test_y, y_pred[:,1]))\n",
    "print(recall_score(df_test_y, y_pred[:,1]))\n",
    "print(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "precision.append(precision_score(df_test_y, y_pred[:,1]))\n",
    "recall.append(recall_score(df_test_y, y_pred[:,1]))\n",
    "F1.append(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=20, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_final=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
    "                                        criterion='gini', max_depth=4,\n",
    "                                        max_features=None, max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=20,\n",
    "                                        min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        presort='deprecated', random_state=None,\n",
    "                                        splitter='best')\n",
    "dt_final.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion matrix : \n",
      "[[204  20]\n",
      " [  2  23]]\n",
      "0.9116465863453815\n",
      "0.5348837209302325\n",
      "0.92\n",
      "0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt_final.predict_proba(df_test_x)\n",
    "threshold=0.2\n",
    "y_pred[y_pred[:,1]>=threshold]=1\n",
    "y_pred[y_pred[:,1]<threshold]=0\n",
    "print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "print(precision_score(df_test_y, y_pred[:,1]))\n",
    "print(recall_score(df_test_y, y_pred[:,1]))\n",
    "print(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "precision.append(precision_score(df_test_y, y_pred[:,1]))\n",
    "recall.append(recall_score(df_test_y, y_pred[:,1]))\n",
    "F1.append(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_final=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
    "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
    "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
    "                     probability=True, random_state=None, shrinking=True,\n",
    "                     tol=0.001, verbose=False)\n",
    "svm_final.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion matrix : \n",
      "[[186  38]\n",
      " [ 24   1]]\n",
      "0.751004016064257\n",
      "0.02564102564102564\n",
      "0.04\n",
      "0.03125\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_final.predict_proba(df_test_x)\n",
    "threshold=0.2\n",
    "y_pred[y_pred[:,1]>=threshold]=1\n",
    "y_pred[y_pred[:,1]<threshold]=0\n",
    "print('Confustion matrix : \\n{}'.format(confusion_matrix(df_test_y, y_pred[:,1])))\n",
    "print(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "print(precision_score(df_test_y, y_pred[:,1]))\n",
    "print(recall_score(df_test_y, y_pred[:,1]))\n",
    "print(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_y, y_pred[:,1]))\n",
    "precision.append(precision_score(df_test_y, y_pred[:,1]))\n",
    "recall.append(recall_score(df_test_y, y_pred[:,1]))\n",
    "F1.append(f1_score(df_test_y, y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_logit=df_raw\n",
    "df_raw_logit.rename(columns = {'Thin F1' : 'Thin_F1','Thin F2' : 'Thin_F2','Thin F3' : 'Thin_F3','Thin F4' : 'Thin_F4'}, inplace = True)\n",
    "df_train_logit, df_test_logit = train_test_split(df_raw_logit, test_size = 0.3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.151028\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Quality   No. Observations:                  581\n",
      "Model:                          Logit   Df Residuals:                      580\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Thu, 18 Mar 2021   Pseudo R-squ.:                  0.5117\n",
      "Time:                        11:59:10   Log-Likelihood:                -87.747\n",
      "converged:                       True   LL-Null:                       -179.70\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -265.0517     47.530     -5.577      0.000    -358.209    -171.894\n",
      "Thin_F4        0.0172      0.002      7.405      0.000       0.013       0.022\n",
      "Thin_F2        0.0627      0.013      4.957      0.000       0.038       0.087\n",
      "Thin_F3        0.0071      0.002      2.869      0.004       0.002       0.012\n",
      "Pressure      98.1691     24.472      4.011      0.000      50.205     146.133\n",
      "Flux90s    -1.222e-17   4.17e-18     -2.928      0.003   -2.04e-17   -4.04e-18\n",
      "ppm           -0.1023      0.030     -3.388      0.001      -0.161      -0.043\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# from_formula 함수를 이용하여 변수 역할 지정\n",
    "# 분석 대상 이벤트 = “1”\n",
    "log_model = Logit.from_formula(\"\"\"Quality ~ Thin_F4 + Thin_F2 + Thin_F3 + Pressure + Flux90s +\n",
    " ppm\"\"\", df_train_logit)\n",
    "# 적합\n",
    "log_result = log_model.fit()\n",
    "# 결과 출력\n",
    "print(log_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859\n",
      "f1: 0.507\n",
      "recall: 0.720\n",
      "\n",
      "Confusion Matrix: \n",
      "[[196  28]\n",
      " [  7  18]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_result.predict(df_test_logit)\n",
    "th = 0.2\n",
    "# 0과 1의 값을 가진 class로 변환\n",
    "y_pred_class = (y_pred > th).astype(int)\n",
    "# 실제 test 데이터의 목표변수와 test 데이터의 예측값 비교\n",
    "print(\"Accuracy: {0:.3f}\".format(accuracy_score(df_test_logit[\"Quality\"], y_pred_class)))\n",
    "print(\"f1: {0:.3f}\".format(f1_score(df_test_logit[\"Quality\"], y_pred_class)))\n",
    "print(\"recall: {0:.3f}\\n\".format(recall_score(df_test_logit[\"Quality\"], y_pred_class)))\n",
    "\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_test_logit[\"Quality\"], y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test.append(accuracy_score(df_test_logit[\"Quality\"], y_pred_class))\n",
    "precision.append(precision_score(df_test_logit[\"Quality\"], y_pred_class))\n",
    "recall.append(recall_score(df_test_logit[\"Quality\"], y_pred_class))\n",
    "F1.append(f1_score(df_test_logit[\"Quality\"], y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9317269076305221,\n",
       " 0.9196787148594378,\n",
       " 0.8995983935742972,\n",
       " 0.9116465863453815,\n",
       " 0.751004016064257,\n",
       " 0.8594377510040161]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6818181818181818,\n",
       " 0.5862068965517241,\n",
       " 0.5,\n",
       " 0.5348837209302325,\n",
       " 0.02564102564102564,\n",
       " 0.391304347826087]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.68, 0.88, 0.92, 0.04, 0.72]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6382978723404256,\n",
       " 0.6296296296296295,\n",
       " 0.6376811594202899,\n",
       " 0.6764705882352942,\n",
       " 0.03125,\n",
       " 0.5070422535211268]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=pd.DataFrame({'accuracy':accuracy_test,'precision':precision,'recall':recall,'F1':F1},index=['XGB','GB','RF','DT','SVM','Logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>GB</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.931727</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.507042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                XGB        GB        RF        DT       SVM  Logistic\n",
       "accuracy   0.931727  0.919679  0.899598  0.911647  0.751004  0.859438\n",
       "precision  0.681818  0.586207  0.500000  0.534884  0.025641  0.391304\n",
       "recall     0.600000  0.680000  0.880000  0.920000  0.040000  0.720000\n",
       "F1         0.638298  0.629630  0.637681  0.676471  0.031250  0.507042"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
