{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.api import Logit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_curve, auc,roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font',family = 'Malgun Gothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"DataSet_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미 변수화\n",
    "df_raw[['Ox_Chamber']]=df_raw[['Ox_Chamber']].astype(str)\n",
    "df_raw[['photo_soft_Chamber']]=df_raw[['photo_soft_Chamber']].astype(str)\n",
    "df_raw[['lithography_Chamber']]=df_raw[['lithography_Chamber']].astype(str)\n",
    "df_raw[['Etching_Chamber']]=df_raw[['Etching_Chamber']].astype(str)\n",
    "df_raw[['Chamber_Num']]=df_raw[['Chamber_Num']].astype(str)\n",
    "df_raw[['Wavelength']]=df_raw[['Wavelength']].astype(str)\n",
    "\n",
    "# wet, dry 구분\n",
    "df_raw.loc[df_raw['type']=='dry','type']=0\n",
    "df_raw.loc[df_raw['type']=='wet','type']=1\n",
    "\n",
    "# Vapor / H2O, O2 구분\n",
    "df_raw.loc[df_raw['Vapor']=='H2O','Vapor']=0\n",
    "df_raw.loc[df_raw['Vapor']=='O2','Vapor']=1\n",
    "\n",
    "# Vapor / H2O, O2 구분\n",
    "df_raw.loc[df_raw['Vapor']=='H2O','Vapor']=0\n",
    "df_raw.loc[df_raw['Vapor']=='O2','Vapor']=1\n",
    "\n",
    "# Wavelength 365, 405, 436\n",
    "df_raw.loc[df_raw['Wavelength']=='365','Wavelength']=0\n",
    "df_raw.loc[df_raw['Wavelength']=='405','Wavelength']=1\n",
    "df_raw.loc[df_raw['Wavelength']=='436','Wavelength']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_before=['type', 'Temp_OXid', 'Vapor', 'ppm','Pressure', 'Oxid_time', 'N2_HMDS', 'pressure_HMDS', 'temp_HMDS','temp_HMDS_bake', 'time_HMDS_bake', 'spin1', 'spin2', 'spin3', 'temp_softbake', 'time_softbake',\n",
    "        'Line_CD','Wavelength', 'Resolution', 'Energy_Exposure',\n",
    "        'Thin F4','Thin F2','Thin F3','Thin F1', 'Temp_Etching','Source_Power', 'Selectivity',\n",
    "        'Flux60s', 'Flux90s', 'Flux160s', 'Flux480s','Flux840s', 'input_Energy', 'Temp_implantation','Furance_Temp', 'RTA_Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppm별로 나눌 필요=> dry(O2), wet(H2O) 별로 모델 나눔\n",
    "df_dummy=pd.get_dummies(df_raw[df_list_before])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "df_x = df_dummy\n",
    "df_y = df_raw['Quality']\n",
    "df_train_x,df_test_x,df_train_y,df_test_y = train_test_split(df_x,df_y,test_size = 0.3,random_state = 1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on train set: 1.000\n",
      "Accuracy on test set: 0.900\n"
     ]
    }
   ],
   "source": [
    "# 그래디언트 부스팅 모델 생성: GradientBoostingClassifier\n",
    "gb_uncustomized = XGBClassifier(random_state=1234)\n",
    "gb_uncustomized.fit(df_train_x, df_train_y)\n",
    "# train 데이터 셋 정확도\n",
    "print(\"Accuracy on train set: {:.3f}\".format(gb_uncustomized.score (df_train_x, df_train_y)))\n",
    "# test 데이터 셋 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gb_uncustomized.score (df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.900\n",
      "\n",
      "Confusion matrix: \n",
      "[[218   6]\n",
      " [ 19   6]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = gb_uncustomized.predict(df_test_x)\n",
    "\n",
    "# train 데이터 셋 정확도\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gb_uncustomized.score(df_train_x, df_train_y)))\n",
    "# test 데이터 셋 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(gb_uncustomized.score(df_test_x, df_test_y)))\n",
    "# confusion matrix\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32432432432432434"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_test_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:48:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:48:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimators</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estimators  TrainAccuracy  TestAccuracy\n",
       "0           1          0.943         0.884\n",
       "1           2          0.954         0.908\n",
       "2           3          0.954         0.892\n",
       "3           4          0.957         0.904\n",
       "4           5          0.955         0.904\n",
       "5           6          0.959         0.908\n",
       "6           7          0.960         0.908\n",
       "7           8          0.971         0.912\n",
       "8           9          0.976         0.912\n",
       "9          10          0.983         0.904"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# n_estimatos: 트리 수 변경: 10~150\n",
    "para_n_tree = [n_tree * 1 for n_tree in range(1, 11)]\n",
    "\n",
    "for v_n_estimators in para_n_tree:\n",
    "    gb = XGBClassifier(n_estimators = v_n_estimators, random_state = 1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_n = pd.DataFrame()\n",
    "df_accuracy_n[\"Estimators\"] = para_n_tree\n",
    "df_accuracy_n[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_n[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# n_estimators별 정확도 테이블\n",
    "df_accuracy_n.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa132489ca0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_n_tree, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_n_tree, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LearningRate</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.05</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.15</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.25</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.30</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.35</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.40</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.45</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LearningRate  TrainAccuracy  TestAccuracy\n",
       "0           0.05          0.947         0.904\n",
       "1           0.10          0.952         0.900\n",
       "2           0.15          0.952         0.900\n",
       "3           0.20          0.947         0.900\n",
       "4           0.25          0.954         0.908\n",
       "5           0.30          0.954         0.908\n",
       "6           0.35          0.954         0.908\n",
       "7           0.40          0.955         0.900\n",
       "8           0.45          0.947         0.908\n",
       "9           0.50          0.948         0.908\n",
       "10          0.55          0.952         0.900\n",
       "11          0.60          0.952         0.900\n",
       "12          0.65          0.954         0.900\n",
       "13          0.70          0.954         0.904\n",
       "14          0.75          0.950         0.904\n",
       "15          0.80          0.955         0.908\n",
       "16          0.85          0.957         0.908\n",
       "17          0.90          0.959         0.908\n",
       "18          0.95          0.957         0.908\n",
       "19          1.00          0.955         0.904\n",
       "20          1.05          0.959         0.896\n",
       "21          1.10          0.959         0.892\n",
       "22          1.15          0.959         0.892\n",
       "23          1.20          0.954         0.896\n",
       "24          1.25          0.954         0.896\n",
       "25          1.30          0.955         0.876\n",
       "26          1.35          0.954         0.876\n",
       "27          1.40          0.954         0.896\n",
       "28          1.45          0.957         0.912"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# learning_rate 학습률 변경: 0.1 ~ 0.9\n",
    "para_lr = [lr * 0.05 for lr in range(1, 30)]\n",
    "\n",
    "for v_learning_rate in para_lr:\n",
    "    gb = XGBClassifier(learning_rate = v_learning_rate, n_estimators = 2, random_state = 1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_lr = pd.DataFrame()\n",
    "df_accuracy_lr[\"LearningRate\"] = para_lr\n",
    "df_accuracy_lr[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_lr[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# LearningRate별 정확도 테이블\n",
    "df_accuracy_lr.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa13229a460>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LearningRate별 정확도 그래프로 확인\n",
    "plt.plot(para_lr, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_lr, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"learning rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth  TrainAccuracy  TestAccuracy\n",
       "0      1          0.916         0.904\n",
       "1      2          0.921         0.908\n",
       "2      3          0.933         0.904\n",
       "3      4          0.940         0.908\n",
       "4      5          0.947         0.904\n",
       "5      6          0.954         0.908\n",
       "6      7          0.954         0.908\n",
       "7      8          0.954         0.908\n",
       "8      9          0.954         0.908\n",
       "9     10          0.954         0.908"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# max_depth: 최대 깊이 변경\n",
    "para_depth = [depth for depth in range(1, 11)]\n",
    "\n",
    "for v_max_depth in para_depth:\n",
    "    gb = XGBClassifier(max_depth = v_max_depth,n_estimators = 2, learning_rate = 0.25,random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_depth = pd.DataFrame()\n",
    "df_accuracy_depth[\"Depth\"] = para_depth\n",
    "df_accuracy_depth[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_depth[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# max_depth별 정확도 테이블\n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa150a19af0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_depth, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_depth, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"depth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:17] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:21] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:21] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:21] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:21] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:21] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:23] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:23] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:23] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:23] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:24] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:24] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:24] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:24] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:24] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:26] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:26] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:26] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:26] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:26] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:54:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinSamplesLeaf</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinSamplesLeaf  TrainAccuracy  TestAccuracy\n",
       "0                1           0.94         0.908\n",
       "1                2           0.94         0.908\n",
       "2                3           0.94         0.908\n",
       "3                4           0.94         0.908\n",
       "4                5           0.94         0.908\n",
       "5                6           0.94         0.908\n",
       "6                7           0.94         0.908\n",
       "7                8           0.94         0.908\n",
       "8                9           0.94         0.908\n",
       "9               10           0.94         0.908\n",
       "10              11           0.94         0.908\n",
       "11              12           0.94         0.908\n",
       "12              13           0.94         0.908\n",
       "13              14           0.94         0.908\n",
       "14              15           0.94         0.908\n",
       "15              16           0.94         0.908\n",
       "16              17           0.94         0.908\n",
       "17              18           0.94         0.908\n",
       "18              19           0.94         0.908\n",
       "19              20           0.94         0.908\n",
       "20              21           0.94         0.908\n",
       "21              22           0.94         0.908\n",
       "22              23           0.94         0.908\n",
       "23              24           0.94         0.908\n",
       "24              25           0.94         0.908\n",
       "25              26           0.94         0.908\n",
       "26              27           0.94         0.908\n",
       "27              28           0.94         0.908\n",
       "28              29           0.94         0.908\n",
       "29              30           0.94         0.908\n",
       "30              31           0.94         0.908\n",
       "31              32           0.94         0.908\n",
       "32              33           0.94         0.908\n",
       "33              34           0.94         0.908\n",
       "34              35           0.94         0.908\n",
       "35              36           0.94         0.908\n",
       "36              37           0.94         0.908\n",
       "37              38           0.94         0.908\n",
       "38              39           0.94         0.908\n",
       "39              40           0.94         0.908\n",
       "40              41           0.94         0.908\n",
       "41              42           0.94         0.908\n",
       "42              43           0.94         0.908\n",
       "43              44           0.94         0.908\n",
       "44              45           0.94         0.908\n",
       "45              46           0.94         0.908\n",
       "46              47           0.94         0.908\n",
       "47              48           0.94         0.908\n",
       "48              49           0.94         0.908\n",
       "49              50           0.94         0.908"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_leaf: 잎사귀 수 제한\n",
    "para_leaf = [n_leaf * 1 for n_leaf in range(1, 51)]\n",
    "\n",
    "for v_min_samples_leaf in para_leaf:\n",
    "    gb = XGBClassifier(min_samples_leaf = v_min_samples_leaf,\n",
    "                                     max_depth = 4, n_estimators = 2, learning_rate = 0.25, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_leaf = pd.DataFrame()\n",
    "df_accuracy_leaf[\"MinSamplesLeaf\"] = para_leaf\n",
    "df_accuracy_leaf[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_leaf[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# min_samples_leaf별 정확도 테이블\n",
    "df_accuracy_leaf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa132203d00>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_leaf, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_leaf, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"min samples leaf\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:55:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinSamplesSplit</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinSamplesSplit  TrainAccuracy  TestAccuracy\n",
       "0               10           0.94         0.908\n",
       "1               20           0.94         0.908\n",
       "2               30           0.94         0.908\n",
       "3               40           0.94         0.908\n",
       "4               50           0.94         0.908\n",
       "5               60           0.94         0.908\n",
       "6               70           0.94         0.908\n",
       "7               80           0.94         0.908\n",
       "8               90           0.94         0.908\n",
       "9              100           0.94         0.908"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_split: 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_split = [n_split * 10 for n_split in range(1, 11)]\n",
    "\n",
    "for v_min_samples_split in para_split:\n",
    "    gb = XGBClassifier(min_samples_split = v_min_samples_split,\n",
    "                                    max_depth = 4,n_estimators = 2, learning_rate = 0.25, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_split = pd.DataFrame()\n",
    "df_accuracy_split[\"MinSamplesSplit\"] = para_split\n",
    "df_accuracy_split[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_split[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# min_samples_leaf별 정확도 테이블\n",
    "df_accuracy_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1321ec5b0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_split, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_split, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"min samples split\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:56:35] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:56:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_iterations  TrainAccuracy  TestAccuracy\n",
       "0              10           0.94         0.908\n",
       "1              20           0.94         0.908\n",
       "2              30           0.94         0.908\n",
       "3              40           0.94         0.908\n",
       "4              50           0.94         0.908\n",
       "5              60           0.94         0.908\n",
       "6              70           0.94         0.908\n",
       "7              80           0.94         0.908\n",
       "8              90           0.94         0.908\n",
       "9             100           0.94         0.908"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_split: 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_iter = [n_iter * 100 for n_iter in range(1, 11)]\n",
    "\n",
    "for v_num_iterations in para_iter:\n",
    "    gb = XGBClassifier(max_depth = 4,n_estimators = 2, learning_rate = 0.25, random_state=1234, num_iterations = v_num_iterations )\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_split = pd.DataFrame()\n",
    "df_accuracy_split[\"num_iterations\"] = para_split\n",
    "df_accuracy_split[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_split[\"TestAccuracy\"] = test_accuracy\n",
    "\n",
    "# min_samples_leaf별 정확도 테이블\n",
    "df_accuracy_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.54188\n",
      "[1]\tvalidation_0-logloss:0.44891\n",
      "Accuracy on training set: 0.940\n",
      "Accuracy on test set: 0.908\n",
      "\n",
      "Confusion matrix: \n",
      "[[219   5]\n",
      " [ 18   7]]\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델\n",
    "gb_final = XGBClassifier( max_depth = 4, n_estimators = 2,\n",
    "                                      learning_rate = 0.25, random_state=1234)\n",
    "evals = [(df_test_x, df_test_y)]\n",
    "gb_final.fit(df_train_x,df_train_y,early_stopping_rounds = 500, eval_metric = 'logloss',\n",
    "             eval_set = evals,verbose = 1)\n",
    "# 예측\n",
    "y_pred = gb_final.predict(df_test_x)\n",
    "\n",
    "# train 데이터 셋 정확도\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gb_final.score(df_train_x, df_train_y)))\n",
    "# test 데이터 셋 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(gb_final.score(df_test_x, df_test_y)))\n",
    "# confusion matrix\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3783783783783784"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_test_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6951579 0.3048421]\n",
      " [0.6951579 0.3048421]\n",
      " [0.6951579 0.3048421]\n",
      " ...\n",
      " [0.6951579 0.3048421]\n",
      " [0.6951579 0.3048421]\n",
      " [0.6951579 0.3048421]]\n",
      "\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "pred_train = gb_final.predict(df_train_x)\n",
    "y_pred_train = gb_final.predict_proba(df_train_x)\n",
    "print(y_pred_train)\n",
    "y_pred_1 = (y_pred_train[:,1] > 0.1)\n",
    "#print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_train_y_wet, y_pred1)))\n",
    "print()\n",
    "print(y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[  0 529]\n",
      " [  0  52]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_train_y, y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.62564373 0.3743563 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6357889  0.3642111 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.62742245 0.37257758]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.47901332 0.5209867 ]\n",
      " [0.613901   0.386099  ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.34005952 0.6599405 ]\n",
      " [0.6357889  0.3642111 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.613901   0.386099  ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.671227   0.32877302]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.671227   0.32877302]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.62564373 0.3743563 ]\n",
      " [0.4967599  0.5032401 ]\n",
      " [0.4655645  0.5344355 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.671227   0.32877302]\n",
      " [0.6357889  0.3642111 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.4468007  0.5531993 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.4655645  0.5344355 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6357889  0.3642111 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.5273659  0.4726341 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.671227   0.32877302]\n",
      " [0.59256303 0.40743697]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.5        0.5       ]\n",
      " [0.34005952 0.6599405 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.613901   0.386099  ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.4655645  0.5344355 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.4655645  0.5344355 ]\n",
      " [0.47901332 0.5209867 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.5273659  0.4726341 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.5        0.5       ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6357889  0.3642111 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.4967599  0.5032401 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.62564373 0.3743563 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.671227   0.32877302]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.671227   0.32877302]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.47901332 0.5209867 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6731312  0.3268688 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.62564373 0.3743563 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6082424  0.39175758]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.671227   0.32877302]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.67933166 0.32066834]\n",
      " [0.6951579  0.3048421 ]\n",
      " [0.6951579  0.3048421 ]]\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-01558ebd5e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "y_pred_test = gb_final.predict_proba(df_test_x)\n",
    "print(y_pred_test)\n",
    "print()\n",
    "y_pred2 = (y_pred_test[:,1] > 0.30)\n",
    "y_pred3 = (y_pred[:,1] > 0.5)\n",
    "print(y_pred2)\n",
    "print()\n",
    "print(y_pred3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[  0 224]\n",
      " [  0  25]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576271186440678"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_test_y,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.36,\n",
       "                               max_delta_step=0, max_depth=7,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=6,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=1234,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe = Pipeline( [ \n",
    "            ('model', XGBClassifier(max_depth = 7, n_estimators = 6, learning_rate = 0.36, random_state = 1234) )] )\n",
    "model_pipe.fit(df_train_x,df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_sample = [sample * 0.1 for sample in range(1, 11)]\n",
    "param_grid1 = {'model__booster':['gbtree'],\n",
    "             'model__subsample':para_sample,\n",
    "             'model__process_type':['default', 'update'],\n",
    "             'model__objective':['binary:logistic'],\n",
    "              'model__scale_pos_weight':[1, 1.1,1.2,1.3,1.4,1.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model',\n",
       "                                        XGBClassifier(base_score=0.5,\n",
       "                                                      booster='gbtree',\n",
       "                                                      colsample_bylevel=1,\n",
       "                                                      colsample_bynode=1,\n",
       "                                                      colsample_bytree=1,\n",
       "                                                      gamma=0, gpu_id=-1,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints='',\n",
       "                                                      learning_rate=0.36,\n",
       "                                                      max_delta_step=0,\n",
       "                                                      max_depth=7,\n",
       "                                                      min_child_weight=1,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints='()',\n",
       "                                                      n_estimators=6, n_job...\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__booster': ['gbtree'],\n",
       "                         'model__objective': ['binary:logistic'],\n",
       "                         'model__process_type': ['default', 'update'],\n",
       "                         'model__scale_pos_weight': [1, 1.1, 1.2, 1.3, 1.4,\n",
       "                                                     1.5],\n",
       "                         'model__subsample': [0.1, 0.2, 0.30000000000000004,\n",
       "                                              0.4, 0.5, 0.6000000000000001,\n",
       "                                              0.7000000000000001, 0.8, 0.9,\n",
       "                                              1.0]},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a GridSearchCV object\n",
    "xg_grid = GridSearchCV(estimator= model_pipe,\n",
    "                       param_grid=param_grid1,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=-1,\n",
    "                       cv=5,\n",
    "                       refit=True, \n",
    "                       return_train_score=True)\n",
    "\n",
    "xg_grid.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = xg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.36,\n",
       "                               max_delta_step=0, max_depth=7,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=6,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               process_type='default', random_state=1234,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1.0, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__booster': 'gbtree',\n",
       " 'model__objective': 'binary:logistic',\n",
       " 'model__process_type': 'default',\n",
       " 'model__scale_pos_weight': 1,\n",
       " 'model__subsample': 1.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred1 = best_model1.predict(df_train_x)\n",
    "y_test_pred1 = best_model1.predict(df_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[221   3]\n",
      " [ 17   8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_test_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       529\n",
      "           1       1.00      0.98      0.99        52\n",
      "\n",
      "    accuracy                           1.00       581\n",
      "   macro avg       1.00      0.99      0.99       581\n",
      "weighted avg       1.00      1.00      1.00       581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_train_y,y_train_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       224\n",
      "           1       0.73      0.32      0.44        25\n",
      "\n",
      "    accuracy                           0.92       249\n",
      "   macro avg       0.83      0.65      0.70       249\n",
      "weighted avg       0.91      0.92      0.91       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test_y,y_test_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
